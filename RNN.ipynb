{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wvDzhJGQIOw"
      },
      "source": [
        "# ✅Importing Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmomDn3cURoc",
        "outputId": "0ba660ab-cbbb-4b17-e6fc-d26d241632ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\منه\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\منه\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\منه\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\منه\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import streamlit as st\n",
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "from datetime import datetime\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string\n",
        "import joblib\n",
        "# Download NLTK resources\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYF6WfgtTos4"
      },
      "source": [
        "# ✅Reading Dataset,Modifications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "23wejXrUI82d"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"sentimentdataset.csv\")\n",
        "\n",
        "data.rename(columns={'Sentiment (Label)': 'Target'}, inplace=True)\n",
        "#removing any spaces and making all of them lower case\n",
        "data['Target'] = data['Target'].str.strip()\n",
        "data['Target'] = data['Target'].str.lower()\n",
        "data['Source'] = data['Source'].str.strip()\n",
        "data['Source'] = data['Source'].str.lower()\n",
        "data['Country'] = data['Country'].str.strip()\n",
        "data['Country'] = data['Country'].str.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "eKzUo0QTJBmU",
        "outputId": "8a3dfb9f-a715-41ca-e3eb-f99d6f6d6d8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>User</th>\n",
              "      <th>Source</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1/15/2023 12:30</td>\n",
              "      <td>User123</td>\n",
              "      <td>twitter</td>\n",
              "      <td>#Nature #Park</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>usa</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Traffic was terrible this morning.           ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>1/15/2023 8:45</td>\n",
              "      <td>CommuterX</td>\n",
              "      <td>twitter</td>\n",
              "      <td>#Traffic #Morning</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>canada</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Just finished an amazing workout! 💪          ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1/15/2023 15:45</td>\n",
              "      <td>FitnessFan</td>\n",
              "      <td>instagram</td>\n",
              "      <td>#Fitness #Workout</td>\n",
              "      <td>20</td>\n",
              "      <td>40</td>\n",
              "      <td>usa</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1/15/2023 18:20</td>\n",
              "      <td>AdventureX</td>\n",
              "      <td>facebook</td>\n",
              "      <td>#Travel #Adventure</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>uk</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1/15/2023 19:55</td>\n",
              "      <td>ChefCook</td>\n",
              "      <td>instagram</td>\n",
              "      <td>#Cooking #Food</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>australia</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                               Text    Target  \\\n",
              "0   0   Enjoying a beautiful day at the park!        ...  positive   \n",
              "1   1   Traffic was terrible this morning.           ...  negative   \n",
              "2   2   Just finished an amazing workout! 💪          ...  positive   \n",
              "3   3   Excited about the upcoming weekend getaway!  ...  positive   \n",
              "4   4   Trying out a new recipe for dinner tonight.  ...   neutral   \n",
              "\n",
              "         Timestamp            User     Source  \\\n",
              "0  1/15/2023 12:30   User123          twitter   \n",
              "1   1/15/2023 8:45   CommuterX        twitter   \n",
              "2  1/15/2023 15:45   FitnessFan     instagram   \n",
              "3  1/15/2023 18:20   AdventureX      facebook   \n",
              "4  1/15/2023 19:55   ChefCook       instagram   \n",
              "\n",
              "                                        Topic  Retweets  Likes    Country  \\\n",
              "0   #Nature #Park                                    15     30        usa   \n",
              "1   #Traffic #Morning                                 5     10     canada   \n",
              "2   #Fitness #Workout                                20     40        usa   \n",
              "3   #Travel #Adventure                                8     15         uk   \n",
              "4   #Cooking #Food                                   12     25  australia   \n",
              "\n",
              "   Year  Month  Day  Hour  \n",
              "0  2023      1   15    12  \n",
              "1  2023      1   15     8  \n",
              "2  2023      1   15    15  \n",
              "3  2023      1   15    18  \n",
              "4  2023      1   15    19  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbocnPatUW_Z"
      },
      "source": [
        "# ✅Changing Target column to only have positive,negative,neutral:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WsePdrmMf7X_"
      },
      "outputs": [],
      "source": [
        "Positive_sentiments = [\n",
        "    'positive', 'happiness', 'joy', 'love', 'amusement', 'enjoyment', 'admiration', 'affection', 'awe',\n",
        "    'acceptance', 'adoration', 'anticipation', 'calmness', 'excitement', 'kind', 'pride', 'elation',\n",
        "    'euphoria', 'contentment', 'serenity', 'gratitude', 'hope', 'empowerment', 'compassion', 'tenderness',\n",
        "    'arousal', 'enthusiasm', 'fulfillment', 'reverence', 'curiosity', 'determination', 'zest', 'hopeful',\n",
        "    'proud', 'grateful', 'empathetic', 'compassionate', 'playful', 'free-spirited', 'inspired', 'confident',\n",
        "    'thrill', 'overjoyed', 'inspiration', 'motivation', 'satisfaction', 'blessed', 'appreciation', 'confidence',\n",
        "    'accomplishment', 'wonderment', 'optimism', 'enchantment', 'intrigue', 'playfuljoy', 'mindfulness', 'dreamchaser',\n",
        "    'elegance', 'whimsy', 'harmony', 'creativity', 'radiance', 'wonder', 'rejuvenation', 'coziness', 'adventure',\n",
        "    'melodic', 'festivejoy', 'innerjourney', 'freedom', 'dazzle', 'artisticburst', 'culinaryodyssey', 'resilience',\n",
        "    'immersion', 'spark', 'marvel', 'positivity', 'kindness', 'friendship', 'success', 'exploration', 'amazement',\n",
        "    'romance', 'captivation', 'tranquility', 'grandeur', 'emotion', 'energy', 'celebration', 'charm', 'ecstasy',\n",
        "    'colorful', 'hypnotic', 'connection', 'iconic', 'journey', 'engagement', 'touched', 'triumph', 'heartwarming',\n",
        "    'solace', 'breakthrough', 'joy in baking', 'envisioning history', 'imagination', 'vibrancy', 'mesmerizing',\n",
        "    'culinary adventure', 'winter magic', 'thrilling journey', \"nature's beauty\", 'celestial wonder', 'creative inspiration',\n",
        "    'runway creativity', \"ocean's freedom\", 'whispers of the past', 'relief','happy','joyfulreunion','adrenaline'\n",
        "]\n",
        "\n",
        "Negative_sentiments = [\n",
        "    'negative', 'anger', 'fear', 'sadness', 'disgust', 'disappointed', 'bitter', 'confusion', 'shame',\n",
        "    'despair', 'grief', 'loneliness', 'jealousy', 'resentment', 'frustration', 'boredom', 'anxiety', 'intimidation',\n",
        "    'helplessness', 'envy', 'regret', 'numbness', 'melancholy', 'ambivalence', 'bitterness', 'yearning', 'fearful',\n",
        "    'apprehensive', 'overwhelmed', 'jealous', 'devastated', 'frustrated', 'envious', 'dismissive', 'heartbreak',\n",
        "    'betrayal', 'suffering', 'emotionalstorm', 'isolation', 'disappointment', 'lostlove', 'exhaustion', 'sorrow',\n",
        "    'darkness', 'desperation', 'ruins', 'desolation', 'loss', 'heartache', 'solitude', 'obstacle', 'sympathy',\n",
        "    'pressure', 'renewed effort', 'miscalculation', 'challenge', 'sad', 'hate', 'bad','bittersweet', 'embarrassed'\n",
        "]\n",
        "\n",
        "Neutral_sentiments = [\n",
        "    'neutral', 'surprise', 'indifference', 'pensive', 'reflection', 'contemplation','mischievous','suspense','nostalgia'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w0HltuLdYHqa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\منه\\AppData\\Local\\Temp\\ipykernel_7700\\966214921.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Target'].replace(word,'Positive',inplace=True)\n",
            "C:\\Users\\منه\\AppData\\Local\\Temp\\ipykernel_7700\\966214921.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Target'].replace(word,'Negative',inplace=True)\n",
            "C:\\Users\\منه\\AppData\\Local\\Temp\\ipykernel_7700\\966214921.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Target'].replace(word,'Neutral',inplace=True)\n"
          ]
        }
      ],
      "source": [
        "for word in data['Target']:\n",
        "  if word in Positive_sentiments:\n",
        "    data['Target'].replace(word,'Positive',inplace=True)\n",
        "  elif word in Negative_sentiments:\n",
        "    data['Target'].replace(word,'Negative',inplace=True)\n",
        "  elif word in Neutral_sentiments:\n",
        "    data['Target'].replace(word,'Neutral',inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lnmG-607UJvc"
      },
      "outputs": [],
      "source": [
        "data.drop(columns = ['Timestamp', 'Hour', 'ID', 'User','Source', 'Retweets','Likes','Country','Year', 'Month', 'Day'], inplace = True)\n",
        "\n",
        "data[['Topic 1', 'Topic 2']] = data['Topic'].str.split(expand=True)\n",
        "data = data.drop('Topic', axis=1)\n",
        "\n",
        "#making both columns lower_case\n",
        "data['Topic 1'] = data['Topic 1'].str.lower()\n",
        "data['Topic 2'] = data['Topic 2'].str.lower()\n",
        "\n",
        "data['Topic 1'] = data['Topic 1'].str.lstrip('#')\n",
        "data['Topic 2'] = data['Topic 2'].str.lstrip('#')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UHYSeJ6aiA_k",
        "outputId": "3e134340-3382-42d9-d971-fa8effc8e186"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>nature</td>\n",
              "      <td>park</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Traffic was terrible this morning.           ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>traffic</td>\n",
              "      <td>morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Just finished an amazing workout! 💪          ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>fitness</td>\n",
              "      <td>workout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>travel</td>\n",
              "      <td>adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>cooking</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text    Target  Topic 1  \\\n",
              "0   Enjoying a beautiful day at the park!        ...  Positive   nature   \n",
              "1   Traffic was terrible this morning.           ...  Negative  traffic   \n",
              "2   Just finished an amazing workout! 💪          ...  Positive  fitness   \n",
              "3   Excited about the upcoming weekend getaway!  ...  Positive   travel   \n",
              "4   Trying out a new recipe for dinner tonight.  ...   Neutral  cooking   \n",
              "\n",
              "     Topic 2  \n",
              "0       park  \n",
              "1    morning  \n",
              "2    workout  \n",
              "3  adventure  \n",
              "4       food  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzl4dNEMABbd"
      },
      "source": [
        "# ✅Encoding The Target column to Unique Values:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I__-pJVJMdM",
        "outputId": "188b958e-3b8a-41e0-f463-afb3c8c81d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 732 entries, 0 to 731\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Text     732 non-null    object\n",
            " 1   Target   732 non-null    int32 \n",
            " 2   Topic 1  732 non-null    int32 \n",
            " 3   Topic 2  732 non-null    int32 \n",
            "dtypes: int32(3), object(1)\n",
            "memory usage: 14.4+ KB\n"
          ]
        }
      ],
      "source": [
        "encoder = LabelEncoder()\n",
        "cols = [\"Target\",\"Topic 1\",\"Topic 2\"]\n",
        "for i in cols:\n",
        "  data[i] = encoder.fit_transform(data[i])\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecnyuUizWFEC"
      },
      "source": [
        "# ✅Preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zvCcqyYWG6r"
      },
      "source": [
        "1. Handling Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MXSJe2sYadG5",
        "outputId": "bc77e855-72d2-494e-a2fb-4b8766259ee4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Traffic was terrible this morning.           ...</td>\n",
              "      <td>0</td>\n",
              "      <td>354</td>\n",
              "      <td>361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Just finished an amazing workout! 💪          ...</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
              "      <td>2</td>\n",
              "      <td>356</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Target  Topic 1  Topic 2\n",
              "0   Enjoying a beautiful day at the park!        ...       2      242      401\n",
              "1   Traffic was terrible this morning.           ...       0      354      361\n",
              "2   Just finished an amazing workout! 💪          ...       2      151      628\n",
              "3   Excited about the upcoming weekend getaway!  ...       2      356        7\n",
              "4   Trying out a new recipe for dinner tonight.  ...       1       87      168"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mXYQ6hMhWJlg"
      },
      "outputs": [],
      "source": [
        "# Tokenization, removing punctuation, lowercasing, removing stopwords, and stemming or lemmatization\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Removing punctuation and lowercasing\n",
        "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
        "\n",
        "    # Removing stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G3fKXpuIXwb6"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing function to the 'Text' column\n",
        "data['Text'] = data['Text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MsjtMbbauSst"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    tag = tag[0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def lemmatize_column(x):\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_entry = [lemmatizer.lemmatize(token, pos=get_wordnet_pos(tag)) for token, tag in nltk.pos_tag(x)]\n",
        "    return lemmatized_entry\n",
        "\n",
        "data[\"Text\"] = data[\"Text\"].apply(lemmatize_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jXGXMbh6uTuv"
      },
      "outputs": [],
      "source": [
        "def join_tokens(tokenized_column):\n",
        "    return tokenized_column.apply(lambda x: ' '.join(x))\n",
        "\n",
        "data['Text'] = join_tokens(data['Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Dc4HhcjVXxNr",
        "outputId": "b9789951-6b36-41c7-bab1-7870510a8ed3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>enjoy beautiful day park</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>traffic terrible morning</td>\n",
              "      <td>0</td>\n",
              "      <td>354</td>\n",
              "      <td>361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>finish amaze workout</td>\n",
              "      <td>2</td>\n",
              "      <td>151</td>\n",
              "      <td>628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>excited upcoming weekend getaway</td>\n",
              "      <td>2</td>\n",
              "      <td>356</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>try new recipe dinner tonight</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Text  Target  Topic 1  Topic 2\n",
              "0          enjoy beautiful day park       2      242      401\n",
              "1          traffic terrible morning       0      354      361\n",
              "2              finish amaze workout       2      151      628\n",
              "3  excited upcoming weekend getaway       2      356        7\n",
              "4     try new recipe dinner tonight       1       87      168"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print the DataFrame to check the result\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM7rlPRXV83F"
      },
      "source": [
        "# ✅RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-ixHAxoNTir",
        "outputId": "9df150a7-2920-4f8f-e249-68a97570abf3"
      },
      "outputs": [],
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# # train_test_split function is used to split data into training and testing sets\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# # Sequential is a model that represents a linear stack of layers to form RNN model\n",
        "# # from keras.models import Sequential\n",
        "# # This line imports Dense layer type from Keras. this layer is building block used to construct neural network architecture.\n",
        "# # from keras.layers import Dense\n",
        "# # to_categorical function is used to convert class vector (integers) to binary class matrix for categorical classification.\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# # Split the dataset into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Target'], test_size=0.25, random_state=42)\n",
        "\n",
        "# # Initialize the TF-IDF vectorizer\n",
        "# vectorizer = TfidfVectorizer()\n",
        "\n",
        "# # Fit the vectorizer to the text data and transform it into TF-IDF vectors\n",
        "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "# X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# # Convert TF-IDF vectors to arrays\n",
        "# X_train_array = X_train_tfidf.toarray()\n",
        "# X_test_array = X_test_tfidf.toarray()\n",
        "\n",
        "# # Convert target labels to categorical\n",
        "\n",
        "# # This line calculates the number of unique classes (targets) in the dataset.\n",
        "# num_classes = len(data['Target'].unique())\n",
        "# # these lines convert the target labels to categorical format\n",
        "# y_train_category = to_categorical(y_train, num_classes=num_classes)\n",
        "# y_test_category = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# # Define the RNN model architecture\n",
        "# model = Sequential()\n",
        "# # This line adds a fully connected Dense layer with 128 units and ReLU activation function to the model. It also specifies the input shape based on the number of features in the training data.\n",
        "# model.add(Dense(128, input_dim=X_train_array.shape[1], activation='relu'))\n",
        "# # This line adds a fully connected Dense layer with softmax activation function to the model. The number of units in this layer is equal to the number of classes, and softmax activation is used for multi-class classification.\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# # This line compiles the model, specifying the loss function, optimizer, and evaluation metric.\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# epochs = 15\n",
        "# batch_size = 64\n",
        "# # This line trains the model on the training data (X_train_array, y_train_category) for a specified number of epochs and batch size. It also uses the validation data (X_test_array, y_test_category) for validation during training\n",
        "# history = model.fit(X_train_array, y_train_category, epochs=epochs, batch_size=batch_size, validation_data=(X_test_array, y_test_category), verbose=2)\n",
        "\n",
        "# # Evaluate the model\n",
        "# _, accuracy = model.evaluate(X_test_array, y_test_category)\n",
        "# print('Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3FCCe_MlLoI",
        "outputId": "9a2b8322-502f-4984-e0fe-4f6a3baf561c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Python\\envs\\test\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
            "found 0 physical cores < 1\n",
            "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
            "  warnings.warn(\n",
            "  File \"d:\\Python\\envs\\test\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
            "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
            "d:\\Python\\envs\\test\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "17/17 - 2s - 88ms/step - accuracy: 0.6388 - loss: 1.0594 - val_accuracy: 0.7486 - val_loss: 1.0265\n",
            "Epoch 2/10\n",
            "17/17 - 0s - 11ms/step - accuracy: 0.9842 - loss: 0.9160 - val_accuracy: 0.8579 - val_loss: 0.9290\n",
            "Epoch 3/10\n",
            "17/17 - 0s - 12ms/step - accuracy: 0.9926 - loss: 0.7072 - val_accuracy: 0.8743 - val_loss: 0.7849\n",
            "Epoch 4/10\n",
            "17/17 - 0s - 11ms/step - accuracy: 0.9954 - loss: 0.4778 - val_accuracy: 0.8798 - val_loss: 0.6258\n",
            "Epoch 5/10\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.9972 - loss: 0.2963 - val_accuracy: 0.8962 - val_loss: 0.4981\n",
            "Epoch 6/10\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.9972 - loss: 0.1818 - val_accuracy: 0.9016 - val_loss: 0.4160\n",
            "Epoch 7/10\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.9972 - loss: 0.1171 - val_accuracy: 0.9016 - val_loss: 0.3706\n",
            "Epoch 8/10\n",
            "17/17 - 0s - 11ms/step - accuracy: 0.9981 - loss: 0.0806 - val_accuracy: 0.9016 - val_loss: 0.3399\n",
            "Epoch 9/10\n",
            "17/17 - 0s - 9ms/step - accuracy: 0.9981 - loss: 0.0587 - val_accuracy: 0.9016 - val_loss: 0.3214\n",
            "Epoch 10/10\n",
            "17/17 - 0s - 10ms/step - accuracy: 0.9991 - loss: 0.0449 - val_accuracy: 0.9016 - val_loss: 0.3093\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3286 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9016393423080444\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['vectorizer.pkl']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Target'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the text data and transform it into TF-IDF vectors\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Convert TF-IDF vectors to arrays\n",
        "X_train_array = X_train_tfidf.toarray()\n",
        "X_test_array = X_test_tfidf.toarray()\n",
        "\n",
        "# Convert target labels to categorical\n",
        "num_classes = len(data['Target'].unique())\n",
        "y_train_category = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_category = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Apply SMOTE for oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_array, y_train_category)\n",
        "\n",
        "# Define the RNN model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train_resampled.shape[1], activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "history = model.fit(X_train_resampled, y_train_resampled, epochs=epochs, batch_size=batch_size, validation_data=(X_test_array, y_test_category), verbose=2)\n",
        "\n",
        "# Evaluate the model\n",
        "_, accuracy = model.evaluate(X_test_array, y_test_category)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "model.save('RNN_Model.h5')\n",
        "joblib.dump(vectorizer, 'vectorizer.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bekJghG4kSbV",
        "outputId": "66d61c76-f7dd-4d31-9188-a1b305739d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "Predicted sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "# Function to make predictions\n",
        "def predict_sentiment(input_text, vectorizer):\n",
        "    # Transform input text into TF-IDF vectors using the provided vectorizer\n",
        "    text_tfidf = vectorizer.transform([input_text])\n",
        "\n",
        "    # Convert TF-IDF vectors to arrays\n",
        "    text_array = text_tfidf.toarray()\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(text_array)\n",
        "\n",
        "    # Get the predicted class (assuming single-label classification)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "    # Map the predicted class back to its original sentiment label\n",
        "    sentiment_labels = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "    predicted_sentiment = sentiment_labels[predicted_class]\n",
        "\n",
        "    return predicted_sentiment\n",
        "\n",
        "# Example usage\n",
        "input_text = \"I cry\"\n",
        "# Assuming you have access to the fitted vectorizer object (let's call it 'vectorizer')\n",
        "predicted_sentiment = predict_sentiment(input_text, vectorizer)\n",
        "print(\"Predicted sentiment:\", predicted_sentiment)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Python\\envs\\test\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "file='RNN'\n",
        "joblib.dump(model,\"RNN\")\n",
        "model=joblib.load(open(\"RNN\",'rb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7xYz85vw58Rc",
        "WOooy0IQLtpD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
