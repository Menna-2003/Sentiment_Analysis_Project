{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wvDzhJGQIOw"
      },
      "source": [
        "# ✅1) Importing Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmomDn3cURoc",
        "outputId": "6788e728-bc3a-4c94-a86f-3a27bd3019b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\منه\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\منه\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\منه\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\منه\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import os\n",
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "from datetime import datetime\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string\n",
        "import joblib\n",
        "# Download NLTK resources\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2G80sNukI5iY"
      },
      "outputs": [],
      "source": [
        "# sia = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DCXvjWFQI8ZL"
      },
      "outputs": [],
      "source": [
        "# def classify_sentiment(word):\n",
        "#     score = sia.polarity_scores(word)['compound']\n",
        "#     if score >= 0.05:\n",
        "#         return \"positive\"\n",
        "#     elif score <= -0.05:\n",
        "#         return \"negative\"\n",
        "#     else:\n",
        "#         return \"neutral\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xMtZjqT-p_0z"
      },
      "outputs": [],
      "source": [
        "Positive_sentiments = [\n",
        "    'positive', 'happiness', 'joy', 'love', 'amusement', 'enjoyment', 'admiration', 'affection', 'awe',\n",
        "    'acceptance', 'adoration', 'anticipation', 'calmness', 'excitement', 'kind', 'pride', 'elation',\n",
        "    'euphoria', 'contentment', 'serenity', 'gratitude', 'hope', 'empowerment', 'compassion', 'tenderness',\n",
        "    'arousal', 'enthusiasm', 'fulfillment', 'reverence', 'curiosity', 'determination', 'zest', 'hopeful',\n",
        "    'proud', 'grateful', 'empathetic', 'compassionate', 'playful', 'free-spirited', 'inspired', 'confident',\n",
        "    'thrill', 'overjoyed', 'inspiration', 'motivation', 'satisfaction', 'blessed', 'appreciation', 'confidence',\n",
        "    'accomplishment', 'wonderment', 'optimism', 'enchantment', 'intrigue', 'playfuljoy', 'mindfulness', 'dreamchaser',\n",
        "    'elegance', 'whimsy', 'harmony', 'creativity', 'radiance', 'wonder', 'rejuvenation', 'coziness', 'adventure',\n",
        "    'melodic', 'festivejoy', 'innerjourney', 'freedom', 'dazzle', 'artisticburst', 'culinaryodyssey', 'resilience',\n",
        "    'immersion', 'spark', 'marvel', 'positivity', 'kindness', 'friendship', 'success', 'exploration', 'amazement',\n",
        "    'romance', 'captivation', 'tranquility', 'grandeur', 'emotion', 'energy', 'celebration', 'charm', 'ecstasy',\n",
        "    'colorful', 'hypnotic', 'connection', 'iconic', 'journey', 'engagement', 'touched', 'triumph', 'heartwarming',\n",
        "    'solace', 'breakthrough', 'joy in baking', 'envisioning history', 'imagination', 'vibrancy', 'mesmerizing',\n",
        "    'culinary adventure', 'winter magic', 'thrilling journey', \"nature's beauty\", 'celestial wonder', 'creative inspiration',\n",
        "    'runway creativity', \"ocean's freedom\", 'whispers of the past', 'relief','happy','joyfulreunion','adrenaline'\n",
        "]\n",
        "\n",
        "Negative_sentiments = [\n",
        "    'negative', 'anger', 'fear', 'sadness', 'disgust', 'disappointed', 'bitter', 'confusion', 'shame',\n",
        "    'despair', 'grief', 'loneliness', 'jealousy', 'resentment', 'frustration', 'boredom', 'anxiety', 'intimidation',\n",
        "    'helplessness', 'envy', 'regret', 'numbness', 'melancholy', 'ambivalence', 'bitterness', 'yearning', 'fearful',\n",
        "    'apprehensive', 'overwhelmed', 'jealous', 'devastated', 'frustrated', 'envious', 'dismissive', 'heartbreak',\n",
        "    'betrayal', 'suffering', 'emotionalstorm', 'isolation', 'disappointment', 'lostlove', 'exhaustion', 'sorrow',\n",
        "    'darkness', 'desperation', 'ruins', 'desolation', 'loss', 'heartache', 'solitude', 'obstacle', 'sympathy',\n",
        "    'pressure', 'renewed effort', 'miscalculation', 'challenge', 'sad', 'hate', 'bad','bittersweet', 'embarrassed'\n",
        "]\n",
        "\n",
        "Neutral_sentiments = [\n",
        "    'neutral', 'surprise', 'indifference', 'pensive', 'reflection', 'contemplation','mischievous','suspense','nostalgia'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYF6WfgtTos4"
      },
      "source": [
        "# ✅ **2) Reading Dataset,Modifications:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "23wejXrUI82d"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"sentimentdataset.csv\")\n",
        "\n",
        "data.rename(columns={'Sentiment (Label)': 'Target'}, inplace=True)\n",
        "\n",
        "#removing any spaces and making all of them lower case\n",
        "data['Target'] = data['Target'].str.strip()\n",
        "data['Target'] = data['Target'].str.lower()\n",
        "data['Source'] = data['Source'].str.strip()\n",
        "data['Source'] = data['Source'].str.lower()\n",
        "data['Country'] = data['Country'].str.strip()\n",
        "data['Country'] = data['Country'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eKzUo0QTJBmU",
        "outputId": "1ec1e23e-bd30-43d0-aab6-974e85d4489c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>User</th>\n",
              "      <th>Source</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1/15/2023 12:30</td>\n",
              "      <td>User123</td>\n",
              "      <td>twitter</td>\n",
              "      <td>#Nature #Park</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>usa</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Traffic was terrible this morning.           ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>1/15/2023 8:45</td>\n",
              "      <td>CommuterX</td>\n",
              "      <td>twitter</td>\n",
              "      <td>#Traffic #Morning</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>canada</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Just finished an amazing workout! 💪          ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1/15/2023 15:45</td>\n",
              "      <td>FitnessFan</td>\n",
              "      <td>instagram</td>\n",
              "      <td>#Fitness #Workout</td>\n",
              "      <td>20</td>\n",
              "      <td>40</td>\n",
              "      <td>usa</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1/15/2023 18:20</td>\n",
              "      <td>AdventureX</td>\n",
              "      <td>facebook</td>\n",
              "      <td>#Travel #Adventure</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>uk</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1/15/2023 19:55</td>\n",
              "      <td>ChefCook</td>\n",
              "      <td>instagram</td>\n",
              "      <td>#Cooking #Food</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>australia</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                               Text    Target  \\\n",
              "0   0   Enjoying a beautiful day at the park!        ...  positive   \n",
              "1   1   Traffic was terrible this morning.           ...  negative   \n",
              "2   2   Just finished an amazing workout! 💪          ...  positive   \n",
              "3   3   Excited about the upcoming weekend getaway!  ...  positive   \n",
              "4   4   Trying out a new recipe for dinner tonight.  ...   neutral   \n",
              "\n",
              "         Timestamp            User     Source  \\\n",
              "0  1/15/2023 12:30   User123          twitter   \n",
              "1   1/15/2023 8:45   CommuterX        twitter   \n",
              "2  1/15/2023 15:45   FitnessFan     instagram   \n",
              "3  1/15/2023 18:20   AdventureX      facebook   \n",
              "4  1/15/2023 19:55   ChefCook       instagram   \n",
              "\n",
              "                                        Topic  Retweets  Likes    Country  \\\n",
              "0   #Nature #Park                                    15     30        usa   \n",
              "1   #Traffic #Morning                                 5     10     canada   \n",
              "2   #Fitness #Workout                                20     40        usa   \n",
              "3   #Travel #Adventure                                8     15         uk   \n",
              "4   #Cooking #Food                                   12     25  australia   \n",
              "\n",
              "   Year  Month  Day  Hour  \n",
              "0  2023      1   15    12  \n",
              "1  2023      1   15     8  \n",
              "2  2023      1   15    15  \n",
              "3  2023      1   15    18  \n",
              "4  2023      1   15    19  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQH8jNItUMuQ"
      },
      "source": [
        "# ✅ **3) Seeing The Unique Values:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOSy2K7fJETZ",
        "outputId": "51d6a953-7b92-480d-9b74-9383621a759a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['positive', 'negative', 'neutral', 'anger', 'fear', 'sadness',\n",
              "       'disgust', 'happiness', 'joy', 'love', 'amusement', 'enjoyment',\n",
              "       'admiration', 'affection', 'awe', 'disappointed', 'surprise',\n",
              "       'acceptance', 'adoration', 'anticipation', 'bitter', 'calmness',\n",
              "       'confusion', 'excitement', 'kind', 'pride', 'shame', 'elation',\n",
              "       'euphoria', 'contentment', 'serenity', 'gratitude', 'hope',\n",
              "       'empowerment', 'compassion', 'tenderness', 'arousal', 'enthusiasm',\n",
              "       'fulfillment', 'reverence', 'despair', 'grief', 'loneliness',\n",
              "       'jealousy', 'resentment', 'frustration', 'boredom', 'anxiety',\n",
              "       'intimidation', 'helplessness', 'envy', 'regret', 'curiosity',\n",
              "       'indifference', 'numbness', 'melancholy', 'nostalgia',\n",
              "       'ambivalence', 'determination', 'zest', 'hopeful', 'proud',\n",
              "       'grateful', 'empathetic', 'compassionate', 'playful',\n",
              "       'free-spirited', 'inspired', 'confident', 'bitterness', 'yearning',\n",
              "       'fearful', 'apprehensive', 'overwhelmed', 'jealous', 'devastated',\n",
              "       'frustrated', 'envious', 'dismissive', 'thrill', 'bittersweet',\n",
              "       'overjoyed', 'inspiration', 'motivation', 'contemplation',\n",
              "       'joyfulreunion', 'satisfaction', 'blessed', 'reflection',\n",
              "       'appreciation', 'confidence', 'accomplishment', 'wonderment',\n",
              "       'optimism', 'enchantment', 'intrigue', 'playfuljoy', 'mindfulness',\n",
              "       'dreamchaser', 'elegance', 'whimsy', 'pensive', 'harmony',\n",
              "       'creativity', 'radiance', 'wonder', 'rejuvenation', 'coziness',\n",
              "       'adventure', 'melodic', 'festivejoy', 'innerjourney', 'freedom',\n",
              "       'dazzle', 'adrenaline', 'artisticburst', 'culinaryodyssey',\n",
              "       'resilience', 'immersion', 'spark', 'marvel', 'heartbreak',\n",
              "       'betrayal', 'suffering', 'emotionalstorm', 'isolation',\n",
              "       'disappointment', 'lostlove', 'exhaustion', 'sorrow', 'darkness',\n",
              "       'desperation', 'ruins', 'desolation', 'loss', 'heartache',\n",
              "       'solitude', 'positivity', 'kindness', 'friendship', 'success',\n",
              "       'exploration', 'amazement', 'romance', 'captivation',\n",
              "       'tranquility', 'grandeur', 'emotion', 'energy', 'celebration',\n",
              "       'charm', 'ecstasy', 'colorful', 'hypnotic', 'connection', 'iconic',\n",
              "       'journey', 'engagement', 'touched', 'suspense', 'triumph',\n",
              "       'heartwarming', 'obstacle', 'sympathy', 'pressure',\n",
              "       'renewed effort', 'miscalculation', 'challenge', 'solace',\n",
              "       'breakthrough', 'joy in baking', 'envisioning history',\n",
              "       'imagination', 'vibrancy', 'mesmerizing', 'culinary adventure',\n",
              "       'winter magic', 'thrilling journey', \"nature's beauty\",\n",
              "       'celestial wonder', 'creative inspiration', 'runway creativity',\n",
              "       \"ocean's freedom\", 'whispers of the past', 'relief', 'embarrassed',\n",
              "       'mischievous', 'sad', 'hate', 'bad', 'happy'], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"Target\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSH2wqHWcNCl",
        "outputId": "6d6c8ead-26d2-4451-f123-e163bc9e16ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive :  45\n",
            "Negative :  4\n",
            "Neutral :  18\n"
          ]
        }
      ],
      "source": [
        "#checking the amount of occarunces for each sentiment\n",
        "print(\"Positive : \",data['Target'].value_counts()['positive'])\n",
        "print(\"Negative : \",data['Target'].value_counts()['negative'])\n",
        "print(\"Neutral : \",data['Target'].value_counts()['neutral'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP761AUuVMhc"
      },
      "source": [
        "# ✅ **4) Checking for Null Values:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHWp-kaFVUZ7",
        "outputId": "033c37c7-8374-400d-a866-51fd85eea42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID           0\n",
            "Text         0\n",
            "Target       0\n",
            "Timestamp    0\n",
            "User         0\n",
            "Source       0\n",
            "Topic        0\n",
            "Retweets     0\n",
            "Likes        0\n",
            "Country      0\n",
            "Year         0\n",
            "Month        0\n",
            "Day          0\n",
            "Hour         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOM-0qkwNjGC",
        "outputId": "38477d94-6920-4312-d63a-7ae3db5250db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Checking for Duplications\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbocnPatUW_Z"
      },
      "source": [
        "# ✅ **5) Changing Target column to only have positive,negative,*neutral*:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w0HltuLdYHqa"
      },
      "outputs": [],
      "source": [
        "#data['Target'] = data['Target'].apply(classify_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LDnbQrw9qKM8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\منه\\AppData\\Local\\Temp\\ipykernel_4956\\966214921.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Target'].replace(word,'Positive',inplace=True)\n",
            "C:\\Users\\منه\\AppData\\Local\\Temp\\ipykernel_4956\\966214921.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Target'].replace(word,'Negative',inplace=True)\n",
            "C:\\Users\\منه\\AppData\\Local\\Temp\\ipykernel_4956\\966214921.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Target'].replace(word,'Neutral',inplace=True)\n"
          ]
        }
      ],
      "source": [
        "for word in data['Target']:\n",
        "  if word in Positive_sentiments:\n",
        "    data['Target'].replace(word,'Positive',inplace=True)\n",
        "  elif word in Negative_sentiments:\n",
        "    data['Target'].replace(word,'Negative',inplace=True)\n",
        "  elif word in Neutral_sentiments:\n",
        "    data['Target'].replace(word,'Neutral',inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh-QLjF8cPlz",
        "outputId": "393e60b8-c68c-4ad0-bd3c-01a347604630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive :  475\n",
            "Negative :  206\n",
            "Neutral :  51\n"
          ]
        }
      ],
      "source": [
        "#checking the amount of occarunces for each sentiment\n",
        "print(\"Positive : \" ,data['Target'].value_counts()['Positive'])\n",
        "print(\"Negative : \" ,data['Target'].value_counts()['Negative'])\n",
        "print(\"Neutral : \" ,data['Target'].value_counts()['Neutral'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6LinWrjzfvX8",
        "outputId": "4b5c9211-0c41-4c18-9499-58d6cd985dc3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>User</th>\n",
              "      <th>Source</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1/15/2023 12:30</td>\n",
              "      <td>User123</td>\n",
              "      <td>twitter</td>\n",
              "      <td>#Nature #Park</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>usa</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Traffic was terrible this morning.           ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>1/15/2023 8:45</td>\n",
              "      <td>CommuterX</td>\n",
              "      <td>twitter</td>\n",
              "      <td>#Traffic #Morning</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>canada</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Just finished an amazing workout! 💪          ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1/15/2023 15:45</td>\n",
              "      <td>FitnessFan</td>\n",
              "      <td>instagram</td>\n",
              "      <td>#Fitness #Workout</td>\n",
              "      <td>20</td>\n",
              "      <td>40</td>\n",
              "      <td>usa</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1/15/2023 18:20</td>\n",
              "      <td>AdventureX</td>\n",
              "      <td>facebook</td>\n",
              "      <td>#Travel #Adventure</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>uk</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>1/15/2023 19:55</td>\n",
              "      <td>ChefCook</td>\n",
              "      <td>instagram</td>\n",
              "      <td>#Cooking #Food</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>australia</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                               Text    Target  \\\n",
              "0   0   Enjoying a beautiful day at the park!        ...  Positive   \n",
              "1   1   Traffic was terrible this morning.           ...  Negative   \n",
              "2   2   Just finished an amazing workout! 💪          ...  Positive   \n",
              "3   3   Excited about the upcoming weekend getaway!  ...  Positive   \n",
              "4   4   Trying out a new recipe for dinner tonight.  ...   Neutral   \n",
              "\n",
              "         Timestamp            User     Source  \\\n",
              "0  1/15/2023 12:30   User123          twitter   \n",
              "1   1/15/2023 8:45   CommuterX        twitter   \n",
              "2  1/15/2023 15:45   FitnessFan     instagram   \n",
              "3  1/15/2023 18:20   AdventureX      facebook   \n",
              "4  1/15/2023 19:55   ChefCook       instagram   \n",
              "\n",
              "                                        Topic  Retweets  Likes    Country  \\\n",
              "0   #Nature #Park                                    15     30        usa   \n",
              "1   #Traffic #Morning                                 5     10     canada   \n",
              "2   #Fitness #Workout                                20     40        usa   \n",
              "3   #Travel #Adventure                                8     15         uk   \n",
              "4   #Cooking #Food                                   12     25  australia   \n",
              "\n",
              "   Year  Month  Day  Hour  \n",
              "0  2023      1   15    12  \n",
              "1  2023      1   15     8  \n",
              "2  2023      1   15    15  \n",
              "3  2023      1   15    18  \n",
              "4  2023      1   15    19  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lnmG-607UJvc"
      },
      "outputs": [],
      "source": [
        "data[['Topic 1', 'Topic 2']] = data['Topic'].str.split(expand=True)\n",
        "data = data.drop('Topic', axis=1)\n",
        "\n",
        "#making both columns lower_case\n",
        "data['Topic 1'] = data['Topic 1'].str.lower()\n",
        "data['Topic 2'] = data['Topic 2'].str.lower()\n",
        "\n",
        "#Converting Year, Month and Day column to one Date column\n",
        "data['date'] = pd.to_datetime(data[['Year', 'Month', 'Day']])\n",
        "\n",
        "data.drop(['Year', 'Month', 'Day', 'Timestamp', 'Hour', 'ID', 'User' , 'Likes' , 'Retweets'], axis=1,inplace =True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZEuoNKRN2DR",
        "outputId": "8b145d9c-7fe7-490e-efcd-14a6fcaf8f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 732 entries, 0 to 731\n",
            "Data columns (total 7 columns):\n",
            " #   Column   Non-Null Count  Dtype         \n",
            "---  ------   --------------  -----         \n",
            " 0   Text     732 non-null    object        \n",
            " 1   Target   732 non-null    object        \n",
            " 2   Source   732 non-null    object        \n",
            " 3   Country  732 non-null    object        \n",
            " 4   Topic 1  732 non-null    object        \n",
            " 5   Topic 2  732 non-null    object        \n",
            " 6   date     732 non-null    datetime64[ns]\n",
            "dtypes: datetime64[ns](1), object(6)\n",
            "memory usage: 40.2+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UHYSeJ6aiA_k",
        "outputId": "88daf199-e317-4433-f4e1-03034b412888"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Source</th>\n",
              "      <th>Country</th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>twitter</td>\n",
              "      <td>usa</td>\n",
              "      <td>#nature</td>\n",
              "      <td>#park</td>\n",
              "      <td>2023-01-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Traffic was terrible this morning.           ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>twitter</td>\n",
              "      <td>canada</td>\n",
              "      <td>#traffic</td>\n",
              "      <td>#morning</td>\n",
              "      <td>2023-01-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Just finished an amazing workout! 💪          ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>instagram</td>\n",
              "      <td>usa</td>\n",
              "      <td>#fitness</td>\n",
              "      <td>#workout</td>\n",
              "      <td>2023-01-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>facebook</td>\n",
              "      <td>uk</td>\n",
              "      <td>#travel</td>\n",
              "      <td>#adventure</td>\n",
              "      <td>2023-01-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>instagram</td>\n",
              "      <td>australia</td>\n",
              "      <td>#cooking</td>\n",
              "      <td>#food</td>\n",
              "      <td>2023-01-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text    Target     Source  \\\n",
              "0   Enjoying a beautiful day at the park!        ...  Positive    twitter   \n",
              "1   Traffic was terrible this morning.           ...  Negative    twitter   \n",
              "2   Just finished an amazing workout! 💪          ...  Positive  instagram   \n",
              "3   Excited about the upcoming weekend getaway!  ...  Positive   facebook   \n",
              "4   Trying out a new recipe for dinner tonight.  ...   Neutral  instagram   \n",
              "\n",
              "     Country   Topic 1     Topic 2       date  \n",
              "0        usa   #nature       #park 2023-01-15  \n",
              "1     canada  #traffic    #morning 2023-01-15  \n",
              "2        usa  #fitness    #workout 2023-01-15  \n",
              "3         uk   #travel  #adventure 2023-01-15  \n",
              "4  australia  #cooking       #food 2023-01-15  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlRgQ9LRUmWe",
        "outputId": "71dd4c37-820f-42e0-a8ee-5d8a99ee6db4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Positive', 'Negative', 'Neutral'], dtype=object)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"Target\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzl4dNEMABbd"
      },
      "source": [
        "# ✅ **6) Encoding The Target column to Unique Values:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apUJ3vlXOhCK",
        "outputId": "4497ae53-110f-4bcd-bba2-715833a7d452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text -- 707\n",
            "Target -- 3\n",
            "Source -- 3\n",
            "Country -- 33\n",
            "Topic 1 -- 372\n",
            "Topic 2 -- 636\n"
          ]
        }
      ],
      "source": [
        "#detecting the unique values of the object type\n",
        "for col in data.select_dtypes('object').columns:\n",
        "    print(f'{col} -- {data[col].nunique()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZZIq-Fnq2Dw",
        "outputId": "f2b9a666-09b1-4a12-91b3-b5aeec44e846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 732 entries, 0 to 731\n",
            "Data columns (total 7 columns):\n",
            " #   Column   Non-Null Count  Dtype         \n",
            "---  ------   --------------  -----         \n",
            " 0   Text     732 non-null    object        \n",
            " 1   Target   732 non-null    int32         \n",
            " 2   Source   732 non-null    int32         \n",
            " 3   Country  732 non-null    int32         \n",
            " 4   Topic 1  732 non-null    int32         \n",
            " 5   Topic 2  732 non-null    int32         \n",
            " 6   date     732 non-null    datetime64[ns]\n",
            "dtypes: datetime64[ns](1), int32(5), object(1)\n",
            "memory usage: 25.9+ KB\n"
          ]
        }
      ],
      "source": [
        "encoder = LabelEncoder()\n",
        "cols = [\"Target\",\"Topic 1\",\"Topic 2\",\"Country\",\"Source\"]\n",
        "for i in cols:\n",
        "  data[i] = encoder.fit_transform(data[i])\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "kXAI5PDxjfTW"
      },
      "outputs": [],
      "source": [
        "#!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kr2JPPe3ikV7"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# from category_encoders import BinaryEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "Nah_01Dnlo4l"
      },
      "outputs": [],
      "source": [
        "#le = LabelEncoder()\n",
        "#data['Target'] = le.fit_transform(data['Target'])\n",
        "#data['Target'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "0I__-pJVJMdM"
      },
      "outputs": [],
      "source": [
        "#To minimize the values in the dataset we used the binary encoding & one hot encoding\n",
        "#one hot encoding for the columns that has low number of unique values\n",
        "#ohe = OneHotEncoder(sparse=False , drop = 'first')\n",
        "#ohe_df = pd.DataFrame(ohe.fit_transform(data[['Source']]) , columns=ohe.get_feature_names_out())\n",
        "#ohe_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DV2xwdGnUiLj"
      },
      "outputs": [],
      "source": [
        "#ohe = OneHotEncoder(sparse=False , drop = 'first')\n",
        "#ohe_df = pd.DataFrame(ohe.fit_transform(data[['Source']]) , columns=ohe.get_feature_names_out())\n",
        "#ohe_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "ufZS0C0xjNOI"
      },
      "outputs": [],
      "source": [
        "#Binary encoding for the columns that has alot of unique values\n",
        "#be = BinaryEncoder()\n",
        "#be_df = be.fit_transform(data[['Country']])\n",
        "#be_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4PrqqD4wjqAM"
      },
      "outputs": [],
      "source": [
        "#data = pd.concat([data , ohe_df , be_df] , axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYmfFIrBo_pQ"
      },
      "source": [
        "# ✅ **7) Function To Encode the Date Column to Unix Timestamp:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Xa4ZxznJpAAC"
      },
      "outputs": [],
      "source": [
        "def to_unix_timestamp(date_string):\n",
        "    date_object = datetime.strptime(date_string, '%m/%d/%Y')\n",
        "    return int(date_object.timestamp())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GfLCsOArpi0F"
      },
      "outputs": [],
      "source": [
        "data['date'] = data['date'].apply(lambda x: pd.to_datetime(x).strftime('%m/%d/%Y'))\n",
        "\n",
        "data['date'] = data['date'].apply(to_unix_timestamp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gapcvmsfq8dQ",
        "outputId": "11589223-aba6-40c7-cd25-3e2ed37fc2c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1673733600\n",
              "1    1673733600\n",
              "2    1673733600\n",
              "3    1673733600\n",
              "4    1673733600\n",
              "Name: date, dtype: int64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['date'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcwBRH8cV2EN"
      },
      "source": [
        "# ✅ **7) Creating Correlation Graph:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "AhUdNhbL33nj",
        "outputId": "edfb99de-cb3f-4ed2-f908-29bbfe944851"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp=data.drop(['Text'],axis=1)\n",
        "sns.heatmap(temp.corr(),annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecnyuUizWFEC"
      },
      "source": [
        "# ✅ **8) Preprocessing:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zvCcqyYWG6r"
      },
      "source": [
        "1. Handling Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "mXYQ6hMhWJlg"
      },
      "outputs": [],
      "source": [
        "# Tokenization, removing punctuation, lowercasing, removing stopwords, and stemming or lemmatization\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Removing punctuation and lowercasing\n",
        "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
        "\n",
        "    # Removing stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "G3fKXpuIXwb6"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing function to the 'Text' column\n",
        "data['Text'] = data['Text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "MsjtMbbauSst"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    tag = tag[0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def lemmatize_column(x):\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_entry = [lemmatizer.lemmatize(token, pos=get_wordnet_pos(tag)) for token, tag in nltk.pos_tag(x)]\n",
        "    return lemmatized_entry\n",
        "\n",
        "data[\"Text\"] = data[\"Text\"].apply(lemmatize_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jXGXMbh6uTuv"
      },
      "outputs": [],
      "source": [
        "def join_tokens(tokenized_column):\n",
        "    return tokenized_column.apply(lambda x: ' '.join(x))\n",
        "\n",
        "data['Text'] = join_tokens(data['Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "Dc4HhcjVXxNr",
        "outputId": "b1e8f548-a338-46c7-ef5c-57719b95d04e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Source</th>\n",
              "      <th>Country</th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>enjoy beautiful day park</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>242</td>\n",
              "      <td>401</td>\n",
              "      <td>1673733600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>traffic terrible morning</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>354</td>\n",
              "      <td>361</td>\n",
              "      <td>1673733600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>finish amaze workout</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>151</td>\n",
              "      <td>628</td>\n",
              "      <td>1673733600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>excited upcoming weekend getaway</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>356</td>\n",
              "      <td>7</td>\n",
              "      <td>1673733600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>try new recipe dinner tonight</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "      <td>168</td>\n",
              "      <td>1673733600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>feel grateful little thing life</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>172</td>\n",
              "      <td>417</td>\n",
              "      <td>1673820000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>rainy day call cozy blanket hot cocoa</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>282</td>\n",
              "      <td>93</td>\n",
              "      <td>1673820000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>new movie release</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>236</td>\n",
              "      <td>369</td>\n",
              "      <td>1673820000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>political discussion heat timeline</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>271</td>\n",
              "      <td>112</td>\n",
              "      <td>1673906400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>miss summer vibe beach day</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330</td>\n",
              "      <td>30</td>\n",
              "      <td>1673906400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>publish new blog post check</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>45</td>\n",
              "      <td>380</td>\n",
              "      <td>1673906400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>feel bit weather today</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>310</td>\n",
              "      <td>200</td>\n",
              "      <td>1673992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>explore city hidden gem</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>69</td>\n",
              "      <td>207</td>\n",
              "      <td>1673992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>new year new fitness goal</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>248</td>\n",
              "      <td>162</td>\n",
              "      <td>1673992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>technology change way live</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>341</td>\n",
              "      <td>299</td>\n",
              "      <td>1674079200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Text  Target  Source  Country  Topic 1  \\\n",
              "0                enjoy beautiful day park       2       2       32      242   \n",
              "1                traffic terrible morning       0       2        5      354   \n",
              "2                    finish amaze workout       2       1       32      151   \n",
              "3        excited upcoming weekend getaway       2       0       31      356   \n",
              "4           try new recipe dinner tonight       1       1        0       87   \n",
              "5         feel grateful little thing life       2       2       13      172   \n",
              "6   rainy day call cozy blanket hot cocoa       2       0        5      282   \n",
              "7                       new movie release       2       1       32      236   \n",
              "8      political discussion heat timeline       0       2       32      271   \n",
              "9              miss summer vibe beach day       1       0        0      330   \n",
              "10            publish new blog post check       2       1       32       45   \n",
              "11                 feel bit weather today       0       2        5      310   \n",
              "12                explore city hidden gem       2       0       31       69   \n",
              "13              new year new fitness goal       2       1       32      248   \n",
              "14             technology change way live       1       2       13      341   \n",
              "\n",
              "    Topic 2        date  \n",
              "0       401  1673733600  \n",
              "1       361  1673733600  \n",
              "2       628  1673733600  \n",
              "3         7  1673733600  \n",
              "4       168  1673733600  \n",
              "5       417  1673820000  \n",
              "6        93  1673820000  \n",
              "7       369  1673820000  \n",
              "8       112  1673906400  \n",
              "9        30  1673906400  \n",
              "10      380  1673906400  \n",
              "11      200  1673992800  \n",
              "12      207  1673992800  \n",
              "13      162  1673992800  \n",
              "14      299  1674079200  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print the DataFrame to check the result\n",
        "data.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xYz85vw58Rc"
      },
      "source": [
        "# ✅ **9) Create numerical features from the text data that the model can understand:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdW8mUSs6Agz",
        "outputId": "fd8d58ce-4c9e-48d6-f682-f452e46fe06d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame with TF-IDF vectors saved to 'tfidf_vectors.csv'\n"
          ]
        }
      ],
      "source": [
        "# Initialize the TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the text data and transform it into TF-IDF vectors\n",
        "tfidf_vectors = vectorizer.fit_transform(data['Text'])\n",
        "\n",
        "# Convert the TF-IDF vectors into a DataFrame\n",
        "tfidf_vector = pd.DataFrame(tfidf_vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Save the DataFrame with TF-IDF vectors to a CSV file\n",
        "tfidf_vector.to_csv('tfidf_vectors.csv', index=False)\n",
        "\n",
        "print(\"DataFrame with TF-IDF vectors saved to 'tfidf_vectors.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "C1XjMxRqnfSy"
      },
      "outputs": [],
      "source": [
        "Data_Final = pd.concat([data, tfidf_vector], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "collapsed": true,
        "id": "0WC0zc4knm10",
        "outputId": "46effe1a-0d78-40e7-9fc0-c2b5c84cc50a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Source</th>\n",
              "      <th>Country</th>\n",
              "      <th>Topic 1</th>\n",
              "      <th>Topic 2</th>\n",
              "      <th>date</th>\n",
              "      <th>ablaze</th>\n",
              "      <th>abstract</th>\n",
              "      <th>abyss</th>\n",
              "      <th>...</th>\n",
              "      <th>yearbook</th>\n",
              "      <th>yearn</th>\n",
              "      <th>yearning</th>\n",
              "      <th>yet</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>zen</th>\n",
              "      <th>zero</th>\n",
              "      <th>zest</th>\n",
              "      <th>zestful</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>enjoy beautiful day park</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>242</td>\n",
              "      <td>401</td>\n",
              "      <td>1673733600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>traffic terrible morning</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>354</td>\n",
              "      <td>361</td>\n",
              "      <td>1673733600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>finish amaze workout</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>151</td>\n",
              "      <td>628</td>\n",
              "      <td>1673733600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>excited upcoming weekend getaway</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>356</td>\n",
              "      <td>7</td>\n",
              "      <td>1673733600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>try new recipe dinner tonight</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "      <td>168</td>\n",
              "      <td>1673733600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Text  Target  Source  Country  Topic 1  \\\n",
              "0          enjoy beautiful day park       2       2       32      242   \n",
              "1          traffic terrible morning       0       2        5      354   \n",
              "2              finish amaze workout       2       1       32      151   \n",
              "3  excited upcoming weekend getaway       2       0       31      356   \n",
              "4     try new recipe dinner tonight       1       1        0       87   \n",
              "\n",
              "   Topic 2        date  ablaze  abstract  abyss  ...  yearbook  yearn  \\\n",
              "0      401  1673733600     0.0       0.0    0.0  ...       0.0    0.0   \n",
              "1      361  1673733600     0.0       0.0    0.0  ...       0.0    0.0   \n",
              "2      628  1673733600     0.0       0.0    0.0  ...       0.0    0.0   \n",
              "3        7  1673733600     0.0       0.0    0.0  ...       0.0    0.0   \n",
              "4      168  1673733600     0.0       0.0    0.0  ...       0.0    0.0   \n",
              "\n",
              "   yearning  yet  york  young  zen  zero  zest  zestful  \n",
              "0       0.0  0.0   0.0    0.0  0.0   0.0   0.0      0.0  \n",
              "1       0.0  0.0   0.0    0.0  0.0   0.0   0.0      0.0  \n",
              "2       0.0  0.0   0.0    0.0  0.0   0.0   0.0      0.0  \n",
              "3       0.0  0.0   0.0    0.0  0.0   0.0   0.0      0.0  \n",
              "4       0.0  0.0   0.0    0.0  0.0   0.0   0.0      0.0  \n",
              "\n",
              "[5 rows x 2100 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data_Final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wRgS-VQ7wF0X"
      },
      "outputs": [],
      "source": [
        "Data_Final.to_csv(\"NEWDATAPRE.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cESQn3LCGP_9"
      },
      "source": [
        "# ✅ **10) Multinomial Naive Bayes Model:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLso2VDsB-f",
        "outputId": "c19afeee-881e-4bca-d6f0-dca805149e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 732 entries, 0 to 731\n",
            "Columns: 2095 entries, Unnamed: 0 to zestful\n",
            "dtypes: float64(2093), int64(2)\n",
            "memory usage: 11.7 MB\n"
          ]
        }
      ],
      "source": [
        "df2 = pd.read_csv('NEWDATAPRE.csv')\n",
        "df2.drop(['Text','date','Topic 1','Topic 2','Source','Country'] , axis = 1 , inplace = True)\n",
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oWT02ftwtFCo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df2.drop(columns=['Target'] , axis = 1)\n",
        "y = df2['Target']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "viT1vdAYRJ2V",
        "outputId": "e41e8318-303f-430e-e3f2-aabb7ec1cbf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.928726035868893\n",
            "Recall: 0.9251700680272109\n",
            "F1-score: 0.9177350060903482\n",
            "train acc 0.9982905982905983\n",
            "test acc 0.9251700680272109\n",
            "Mean Accuracy: 0.7703196347031963\n"
          ]
        }
      ],
      "source": [
        "#NAIIVE BAY'S MODEL IMPLEMENTATION\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Initialize and train Multinomial Naive Bayes classifier\n",
        "clf = MultinomialNB(alpha = 0.001 , force_alpha = True)\n",
        "clf.fit(X_train, y_train)\n",
        "y_train_prd = clf.predict(X_train)\n",
        "y_test_prd = clf.predict(X_test)\n",
        "# Evaluate performance\n",
        "precision = precision_score(y_test, y_test_prd, average='weighted')\n",
        "recall = recall_score(y_test, y_test_prd, average='weighted')\n",
        "f1 = f1_score(y_test, y_test_prd, average='weighted')\n",
        "\n",
        "#print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "\n",
        "print(\"train acc\" , accuracy_score(y_true=y_train , y_pred=y_train_prd))\n",
        "print(\"test acc\"  ,  accuracy_score(y_true=y_test , y_pred=y_test_prd))\n",
        "\n",
        "# Print cross-validation scores\n",
        "#print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean Accuracy:\", scores.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['naive_bayes_model.pkl']"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(clf, 'naive_bayes_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYWTf5WaGZPR"
      },
      "source": [
        "# ✅ **11) Logistic Regression Model:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vYAj4tXG0gsg"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1aqVnMoLL7wM",
        "outputId": "0fb3af88-648d-46d5-ee51-090b723b8488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 732 entries, 0 to 731\n",
            "Columns: 2101 entries, Unnamed: 0 to zestful\n",
            "dtypes: float64(2093), int64(7), object(1)\n",
            "memory usage: 11.7+ MB\n"
          ]
        }
      ],
      "source": [
        "logistic_data = pd.read_csv('NEWDATAPRE.csv')\n",
        "logistic_data.info()\n",
        "logistic_data.drop(['Text','date','Topic 2','Source','Country'] , axis = 1 , inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "h6rUC-jML_sp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = logistic_data.drop(columns=['Target'] , axis = 1)\n",
        "y = logistic_data['Target']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Wa7A6gze0gy8"
      },
      "outputs": [],
      "source": [
        "LR = LogisticRegression(penalty = 'l2' , C =6, tol = 1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "6RHNBviq1uOo",
        "outputId": "d6f0a605-200c-4228-8e91-0c40ad30e9b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Python\\envs\\test\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=6, tol=1e-05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=6, tol=1e-05)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=6, tol=1e-05)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LR.fit(X_train , y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "shU9NfOJ1xgI"
      },
      "outputs": [],
      "source": [
        "y_train_prd = LR.predict(X_train)\n",
        "y_test_prd = LR.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_kuiKlO1xeA",
        "outputId": "404471f5-048e-4228-d685-e38129961373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9777777777777777\n",
            "0.8435374149659864\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(y_true=y_train , y_pred=y_train_prd))\n",
        "print(accuracy_score(y_true=y_test , y_pred=y_test_prd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['LR_model.pkl']"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(LR, 'LR_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ujs8zoEG6Mz"
      },
      "source": [
        "# ✅ **12) Support Vector Machines (SVM):**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exV4XFCSHE1p",
        "outputId": "9d88ef0b-15ab-40b5-da1b-5ae2c92e223f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Train: 0.9675213675213675\n",
            "Accuracy Test: 0.9591836734693877\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data_svm = pd.read_csv(\"NEWDATAPRE.csv\")\n",
        "# Assuming 'Text' column contains textual data and 'Target' column contains the sentiment labels\n",
        "X = data_svm['Text']\n",
        "y = data_svm['Target']\n",
        "\n",
        "# Convert text data to numerical representation using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features as needed\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# Now proceed with train-test split and fitting the classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=80)\n",
        "\n",
        "# Initialize SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred_test = clf.predict(X_test)\n",
        "y_pred_train = clf.predict(X_train)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Accuracy Train:\", accuracy_train)\n",
        "print(\"Accuracy Test:\", accuracy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['SVM_model.pkl']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(clf, 'SVM_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtDxazRHEWtK"
      },
      "source": [
        "# ✅ **13)Recurrent Neural Networks (RNNs):**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LROFlZyvEgZk",
        "outputId": "5cf78999-4d9f-43ed-a87f-4cf7be172f56"
      },
      "outputs": [],
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# # Split the dataset into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Target'], test_size=0.25, random_state=42)\n",
        "\n",
        "# # Initialize the TF-IDF vectorizer\n",
        "# vectorizer = TfidfVectorizer()\n",
        "\n",
        "# # Fit the vectorizer to the text data and transform it into TF-IDF vectors\n",
        "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "# X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# # Convert TF-IDF vectors to arrays\n",
        "# X_train_array = X_train_tfidf.toarray()\n",
        "# X_test_array = X_test_tfidf.toarray()\n",
        "\n",
        "# # Apply SMOTE for oversampling\n",
        "# smote = SMOTE(random_state=42)\n",
        "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_array, y_train)\n",
        "\n",
        "# # Define the RNN model architecture\n",
        "# model = Sequential()\n",
        "# model.add(Dense(128, input_dim=X_train_resampled.shape[1], activation='relu'))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# epochs = 10\n",
        "# batch_size = 64\n",
        "# history = model.fit(X_train_resampled, y_train_resampled, epochs=epochs, batch_size=batch_size, validation_data=(X_test_array, y_test), verbose=2)\n",
        "\n",
        "# # Evaluate the model\n",
        "# _, accuracy = model.evaluate(X_test_array, y_test)\n",
        "# print('Accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "769nOEzYkxtE",
        "outputId": "30c29359-47a7-4fab-b383-f4bbb5cd0972"
      },
      "outputs": [],
      "source": [
        "# # Function to make predictions\n",
        "# def predict_sentiment(input_text, vectorizer):\n",
        "#     # Transform input text into TF-IDF vectors using the provided vectorizer\n",
        "#     text_tfidf = vectorizer.transform([input_text])\n",
        "\n",
        "#     # Convert TF-IDF vectors to arrays\n",
        "#     text_array = text_tfidf.toarray()\n",
        "\n",
        "#     # Make predictions\n",
        "#     predictions = model.predict(text_array)\n",
        "\n",
        "#     # Get the predicted class (assuming single-label classification)\n",
        "#     predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "#     # Map the predicted class back to its original sentiment label\n",
        "#     sentiment_labels = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "#     predicted_sentiment = sentiment_labels[predicted_class]\n",
        "\n",
        "#     return predicted_sentiment\n",
        "\n",
        "# # Example usage\n",
        "# input_text = \"I fail  \"\n",
        "# # Assuming you have access to the fitted vectorizer object (let's call it 'vectorizer')\n",
        "# predicted_sentiment = predict_sentiment(input_text, vectorizer)\n",
        "# print(\"Predicted sentiment:\", predicted_sentiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjVsuz6ptqSE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
